---
layout: post
title: Artificial Intelligence
date: 2020-01-11
cover_image: 2021-05-31-flameshot.gif
author: Yongguang Lin
categories: artificial intelligence
last_modified_at: 2023-02-12
excerpt_separator: <!--more-->
---

Die Idee der künstlichen Intelligenz (KI) - Systeme, die so fortschrittlich sind, dass sie die menschliche Kognition nachahmen oder übertreffen können - wurde erstmals 1950 bekannt, als der britische Informatiker [Alan Turing](https://de.wikipedia.org/wiki/Alan_Turing) ein "Nachahmungsspiel" vorschlug, um zu prüfen, ob ein Computer den Menschen vorgaukeln kann, er würde mit einem anderen Menschen kommunizieren. Bald darauf entwickelten Forscher an der Princeton University in New Jersey [MADALINE](https://en.wikipedia.org/wiki/ADALINE), das erste künstliche neuronale Netz, das auf ein reales Problem angewendet wurde. Ihr System, das dem Gehirn und dem Nervensystem nachempfunden war, lernte durch Versuch und Irrtum, ein Labyrinth zu lösen.
<!--more-->

![Alan Turin](https://lh3.googleusercontent.com/gdZZcYRPGK-8ACkyOkLPEDctQX3OqcECWWH98VyfuUZuYRJlt5HOFgpe2PLFH7Fbhy_jE4x9V288OSj4MyQUDsQIuIudXrn5_4UGbYLfNFK0dCph99nS42obq35pAIe-tw=w128)


Seitdem wurde der Aufstieg der KI durch exponentiell schnellere und leistungsfähigere Computer und große, komplexe Datensätze ermöglicht. Anwendungen wie das maschinelle Lernen, bei dem ein System Muster in großen Datenmengen erkennt, haben gezeigt, dass die KI praktisch und profitabel sein kann.

Heute bildet die KI die Grundlage für Computersysteme, die Aufgaben wie Spracherkennung und Übersetzung auf Smartphones, das Steuern von fahrerlosen Autos und die Kontrolle von Robotern, die Aufgaben in Haushalten und Fabriken automatisieren, übernehmen. In der Forschung wird KI in einer wachsenden Zahl von Anwendungen eingesetzt, z. B. bei der Verarbeitung der enormen Datenmengen, die Bereichen wie Astronomie und Genomik zugrunde liegen, bei der Erstellung von Klimamodellen und Wettervorhersagen sowie bei der Erkennung von Krankheitsanzeichen in der medizinischen Bildgebung.

Einrichtungen in Deutschland, wie die [Fraunhofer-Gesellschaft](https://www.fraunhofer.de/), Europas größte anwendungsorientierte Forschungsorganisation, haben den Schwerpunkt auf Industrie 4.0 gelegt, eine nationale strategische Initiative der deutschen Regierung zur Einführung von mehr digitaler Innovation und fortschrittlicher Robotik in der Fertigung und im Lieferkettenmanagement.

In China könnte die Fähigkeit von KI-Systemen, öffentliche Räume zu überwachen und den Internetverkehr zu scannen, um die Absichten der Nutzer herauszufinden, dem Staat bessere Instrumente zur sozialen Kontrolle an die Hand geben und seine Möglichkeiten zur Überwachung der Bevölkerung oder zur Zensur von Informationen verbessern. Selbst in Ländern, die ihre Bevölkerung nicht offiziell überwachen, wird Gesichtserkennungs-technologie, wie die des in New York ansässigen Unternehmens [Clearview AI](https://www.clearview.ai/), von den Strafverfolgungsbehörden zur Identifizierung von Verdächtigen eingesetzt.

Die verschiedenen Teilbereiche der KI-Forschung sind auf bestimmte Ziele und den Einsatz bestimmter Werkzeuge ausgerichtet. Zu den traditionellen Zielen der KI-Forschung gehören logisches Denken, Wissensrepräsentation, Planung, Lernen, Verarbeitung natürlicher Sprache, Wahrnehmung und die Fähigkeit, Objekte zu bewegen und zu manipulieren. Allgemeine Intelligenz (die Fähigkeit, ein beliebiges Problem zu lösen) gehört zu den langfristigen Zielen des Fachgebiets. Um diese Probleme zu lösen, haben KI-Forscher eine breite Palette von Problemlösungstechniken angepasst und integriert, darunter Suche und mathematische Optimierung, formale Logik, künstliche neuronale Netze und Methoden auf der Grundlage von Statistik, Wahrscheinlichkeit und Wirtschaft. KI stützt sich auch auf Informatik, Psychologie, Linguistik, Philosophie und viele andere Bereiche. 


# Erklärbare KI

Künstliche Intelligenz (KI) beeinflusst unser tägliches Leben in vielerlei Hinsicht. Gesichtserkennungssysteme, künstliche Assistenten und Vorhersagemodelle werden fast überall eingesetzt. KI kommt in vielen Branchen zum Einsatz, z. B. im Bildungswesen, im Gesundheitswesen, in der Automobilindustrie, in der Fertigung und bei der Strafverfolgung. Die Entscheidungen und Vorhersagen, die von KI-gestützten Systemen getroffen werden, werden immer wichtiger und sind in vielen Fällen entscheidend für Leben und Tod. Dies gilt insbesondere für KI-Systeme im Gesundheitswesen, fahrerlose Autos oder auch Drohnen, die im Krieg eingesetzt werden.

Die Funktionsweise dieser KI-Modelle ist jedoch sowohl für den Normalbürger als auch für Fachleute nicht verständlich. Wenn ein künstliches neuronales Netz anhand eines Bildes eine Vorhersage trifft, ob es sich um eine Katze oder einen Hund handelt, ist es nicht offensichtlich, aufgrund welcher Merkmale oder Eigenschaften diese Entscheidung getroffen wird. Diese Entscheidung ist jedoch nicht so entscheidend für unser Leben wie die Vorhersage, ob es sich bei dem Bild einer Tumorzelle um einen bösartigen oder gutartigen Tumor handelt. Wir würden natürlich gerne wissen, auf der Grundlage welcher Parameter diese Entscheidung getroffen wird.

Im Gesundheitswesen ist die Erklärbarkeit von KI von größter Bedeutung. Früher wurden Modelle des maschinellen Lernens und des Deep Learning als Blackboxen behandelt, die Eingaben entgegennahmen und Entscheidungen trafen, um eine bestimmte Ausgabe zu liefern, wobei nicht klar war, auf der Grundlage welcher Parameter diese Entscheidungen getroffen wurden. Mit dem zunehmenden Einsatz von KI in unserem täglichen Leben und der Tatsache, dass KI Entscheidungen trifft, die unser Leben und unseren Tod beeinflussen, wie z. B. autonome Autos oder Software zur Krebsvorhersage, ist der Bedarf an Erklärbarkeit in der KI gestiegen. Seit den ersten tödlichen Unfall eines seiner selbstfahrenden Autos des US-amerikanischen Elektrofahrzeugherstellers [Tesla](https://www.tesla.com/) in 2016 wurde weitere Unfälle in Verbindung mit fahrerlosen Auto gebracht.

Daher müssen wir als Menschen in der Lage sein, vollständig zu verstehen, wie Entscheidungen getroffen werden, damit wir den Entscheidungen von KI-Systemen vertrauen können. Der Mangel an Erklärbarkeit und Vertrauen behindert unsere Fähigkeit, KI-Systemen voll zu vertrauen. Wir wollen, dass Computersysteme wie erwartet funktionieren und transparente Erklärungen und Gründe für ihre Entscheidungen liefern. Dies wird als erklärbare KI bezeichnet.

Je größer die möglichen Folgen von KI-basierten Ergebnissen sind, desto größer ist der Bedarf an erklärbarer KI.

Erklärbare KI ist ein neues und aufstrebendes Gebiet im Bereich der KI und des maschinellen Lernens. Es ist sehr wichtig, bei den Menschen Vertrauen in die von KI-Modellen getroffenen Entscheidungen zu schaffen. Dies ist nur möglich, wenn die Blackbox der ML-Modelle transparenter gemacht wird.Erklärbare KI

Künstliche Intelligenz (KI) beeinflusst unser tägliches Leben in vielerlei Hinsicht. Gesichtserkennungssysteme, künstliche Assistenten und Vorhersagemodelle werden fast überall eingesetzt. KI kommt in vielen Branchen zum Einsatz, z. B. im Bildungswesen, im Gesundheitswesen, in der Automobilindustrie, in der Fertigung und bei der Strafverfolgung. Die Entscheidungen und Vorhersagen, die von KI-gestützten Systemen getroffen werden, werden immer wichtiger und sind in vielen Fällen entscheidend für Leben und Tod. Dies gilt insbesondere für KI-Systeme im Gesundheitswesen, fahrerlose Autos oder auch Drohnen, die im Krieg eingesetzt werden.

Die Funktionsweise dieser KI-Modelle ist jedoch sowohl für den Normalbürger als auch für Fachleute nicht verständlich. Wenn ein künstliches neuronales Netz anhand eines Bildes eine Vorhersage trifft, ob es sich um eine Katze oder einen Hund handelt, ist es nicht offensichtlich, aufgrund welcher Merkmale oder Eigenschaften diese Entscheidung getroffen wird. Diese Entscheidung ist jedoch nicht so entscheidend für unser Leben wie die Vorhersage, ob es sich bei dem Bild einer Tumorzelle um einen bösartigen oder gutartigen Tumor handelt. Wir würden natürlich gerne wissen, auf der Grundlage welcher Parameter diese Entscheidung getroffen wird.

Im Gesundheitswesen ist die Erklärbarkeit von KI von größter Bedeutung. Früher wurden Modelle des maschinellen Lernens und des Deep Learning als Blackboxen behandelt, die Eingaben entgegennahmen und Entscheidungen trafen, um eine bestimmte Ausgabe zu liefern, wobei nicht klar war, auf der Grundlage welcher Parameter diese Entscheidungen getroffen wurden. Mit dem zunehmenden Einsatz von KI in unserem täglichen Leben und der Tatsache, dass KI Entscheidungen trifft, die unser Leben und unseren Tod beeinflussen, wie z. B. autonome Autos oder Software zur Krebsvorhersage, ist der Bedarf an Erklärbarkeit in der KI gestiegen.

Als Menschen müssen wir in der Lage sein, vollständig zu verstehen, wie Entscheidungen getroffen werden, damit wir den Entscheidungen von KI-Systemen vertrauen können. Der Mangel an Erklärbarkeit und Vertrauen behindert unsere Fähigkeit, KI-Systemen voll zu vertrauen. Wir wollen, dass Computersysteme wie erwartet funktionieren und transparente Erklärungen und Gründe für ihre Entscheidungen liefern. Dies wird als erklärbare KI bezeichnet.

Je größer die möglichen Folgen von KI-basierten Ergebnissen sind, desto größer ist der Bedarf an erklärbarer KI.

Erklärbare KI ist ein neues und aufstrebendes Gebiet im Bereich der KI und des maschinellen Lernens. Es ist sehr wichtig, bei den Menschen Vertrauen in die von KI-Modellen getroffenen Entscheidungen zu schaffen. Dies ist nur möglich, wenn die Blackbox der ML-Modelle transparenter gemacht wird.